{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chlin1/test/blob/master/Reinforcement_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9towHgjbCAZw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reinforcement learning"
      ]
    },
    {
      "metadata": {
        "id": "STw83rqfQfq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btye2XZkCJ2S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 10 states and 2 actions \\\n",
        " 10 states: Consider 10 tiles with a hole in tile-0 and a beer in tile-6 \\\n",
        " 2 actions: move left or move right \\\n",
        " get reward - 100 if hit the hole from 1+left and 100 if hit the beer from 5+right mor 7+left \\\n",
        " \n",
        " ref: https://itnext.io/reinforcement-learning-with-q-tables-5f11168862c8\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "yVeFCPRxB_6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 10 states x 2 actions\n",
        "environment_matrix = [[None, 0],\n",
        "                  [-100, 0],\n",
        "                  [0, 0],\n",
        "                  [0, 0],\n",
        "                  [0, 0],\n",
        "                  [0, 100],\n",
        "                  [0, 0],\n",
        "                  [100, 0],\n",
        "                  [0, 0],\n",
        "                  [0, None]]\n",
        "\n",
        "# quality matrix\n",
        "q_matrix = [[0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KT_X6KYTDSDk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "WvzpQ3XuDTDf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "win_loss_states = [0,6]\n",
        "\n",
        "# input current state and it will return all possible actions\n",
        "# for state 0/ 9 only right/ left action\n",
        "def getAllPossibleNextAction(cur_pos):\n",
        "    step_matrix = [x != None for x in environment_matrix[cur_pos]]\n",
        "    action = []\n",
        "    if(step_matrix[0]):\n",
        "        action.append(0)    \n",
        "    if(step_matrix[1]):\n",
        "        action.append(1)\n",
        "    return(action)\n",
        "  \n",
        "# if current state is 6, it returns True  \n",
        "def isGoalStateReached(cur_pos):\n",
        "    return (cur_pos in [6])\n",
        "  \n",
        "# input current state and the action and it will return the next state  \n",
        "def getNextState(cur_pos, action):\n",
        "    if (action == 0):\n",
        "        return cur_pos - 1\n",
        "    else:\n",
        "        return cur_pos + 1\n",
        "      \n",
        "# if state is 0 or 6, the game is over and return True      \n",
        "def isGameOver(cur_pos):\n",
        "    return cur_pos in win_loss_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoCCNS9hNabw",
        "colab_type": "code",
        "outputId": "c4c155f4-c8b1-40cd-f6ec-26819dc85e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "# discount factor and learning rate\n",
        "discount = 0.9\n",
        "learning_rate = 0.1\n",
        "\n",
        "# train 1000 epochs\n",
        "for _ in range(1000):\n",
        "    # get starting place\n",
        "    cur_pos = random.choice([0,1,2,3,4,5,6,7,8,9])\n",
        "    # while goal state is not reached\n",
        "    while(not isGameOver(cur_pos)):\n",
        "        # get all possible next states from cur_step\n",
        "        possible_actions = getAllPossibleNextAction(cur_pos)\n",
        "        # select any one action randomly\n",
        "        action = random.choice(possible_actions)\n",
        "        # find the next state corresponding to the action selected\n",
        "        next_state = getNextState(cur_pos, action)\n",
        "        # update the q_matrix\n",
        "        q_matrix[cur_pos][action] = q_matrix[cur_pos][action] + learning_rate * (environment_matrix[cur_pos][action] + discount * max(q_matrix[next_state]) - q_matrix[cur_pos][action])\n",
        "        # go to next state\n",
        "        cur_pos = next_state\n",
        "    # print status\n",
        "    #print(\"Episode \", _ , \" done\")\n",
        "print(q_matrix)\n",
        "print(\"Training done...\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0], [-99.99999999999994, 65.60999999999973], [59.04899999999972, 72.89999999999978], [65.60999999999973, 80.99999999999983], [72.89999999999978, 89.99999999999989], [80.99999999999983, 99.99999999999994], [0, 0], [99.99999999999994, 80.99999999999983], [89.99999999999989, 72.89999999999978], [80.99999999999983, 0]]\n",
            "Training done...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OkAHqf3NNcg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "c27719f1-423d-4b82-86e0-c44585bb0cd5"
      },
      "cell_type": "code",
      "source": [
        "# at any state, choose the acion with higher value and you till reach the tile with beer.\n",
        "q_matrix"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0],\n",
              " [-99.99999999985914, 65.60999798615656],\n",
              " [59.04899650042512, 72.89999997308469],\n",
              " [65.60999994330666, 80.99999999225268],\n",
              " [72.8999999791936, 89.99999999526678],\n",
              " [80.99999995581824, 99.99999999730835],\n",
              " [0, 0],\n",
              " [99.9999999999977, 80.99999999998266],\n",
              " [89.99999999999547, 72.89999999998747],\n",
              " [80.99999999999228, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ujzYgvc3RGlt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}